{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65885728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from zipfile import ZipFile\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97f0ce11",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train=\"C:/Users/abhin/Downloads/train.zip\"\n",
    "with ZipFile(dataset_train,'r') as zip:\n",
    "    zip.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22a8b289",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path=f\"C:/Users/abhin/Downloads\"\n",
    "os.makedirs(folder_path,exist_ok=True)\n",
    "\n",
    "confusion_image_path=os.path.join(folder_path,'confusion matrix.png')\n",
    "classification_file_path=os.path.join(folder_path,'classification_report.txt')\n",
    "model_file_path=os.path.join(folder_path,\"svm_model.pkl\")\n",
    "\n",
    "train_dir=\"C:\\\\Users\\\\abhin\\\\Downloads\\\\train\\\\train\"\n",
    "\n",
    "test_dir=r\"C:\\\\Users\\\\abhin\\\\Downloads\\\\test1\\\\test1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d86ea023",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Train Images: 100%|██████████| 25000/25000 [02:23<00:00, 174.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 25000 images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the directory containing the images\n",
    "#train_dir = r\"C:\\\\Users\\\\abhin\\\\Downloads\\\\train\\\\train\"  # Adjust this path as needed\n",
    "\n",
    "# Initialize lists for features and labels\n",
    "features = []\n",
    "labels = []\n",
    "image_size = (50, 50)  # Desired image size\n",
    "\n",
    "# Get the list of image files in the directory\n",
    "train_images = os.listdir(train_dir)\n",
    "\n",
    "# Process each image file\n",
    "for image in tqdm(train_images, desc=\"Processing Train Images\"):\n",
    "    # Create the full path to the image file\n",
    "    image_path = os.path.join(train_dir, image)\n",
    "    \n",
    "    # Check if the file is an image (optional)\n",
    "    if not image.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        continue\n",
    "    \n",
    "    # Determine the label based on the filename\n",
    "    if image.startswith('cat'):\n",
    "        label = 0\n",
    "    else:\n",
    "        label = 1\n",
    "    \n",
    "    # Read and process the image\n",
    "    image_read = cv2.imread(image_path)  # Read the image\n",
    "    if image_read is not None:\n",
    "        image_resized = cv2.resize(image_read, image_size)  # Resize the image\n",
    "        image_normalized = image_resized / 255.0  # Normalize the image\n",
    "        image_flatten = image_normalized.flatten()  # Flatten the image\n",
    "        features.append(image_flatten)  # Append the processed image to the list\n",
    "        labels.append(label)  # Append the label to the list\n",
    "\n",
    "# Output the number of processed images\n",
    "print(f\"Processed {len(features)} images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b071cc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2b76ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features=np.asarray(features)\n",
    "labels=np.asarray(labels)\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(features,labels,test_size=0.2,shuffle=True,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26774268",
   "metadata": {},
   "outputs": [],
   "source": [
    "del features\n",
    "del labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc31a73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components=0.8\n",
    "pca=PCA(n_components=n_components)\n",
    "svm=SVC()\n",
    "pca=PCA(n_components=n_components, random_state=42)\n",
    "pipeline=Pipeline([('pca',pca),\n",
    "                   ('svm',svm)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f8b203c",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid={\n",
    "    'pca__n_components':[2,1,0.9,0.8],\n",
    "    'svm__kernel':['linear','rbf','poly','sigmoid'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da56d208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[CV 1/3] END pca__n_components=2, svm__kernel=linear;, score=0.528 total time=  37.9s\n",
      "[CV 2/3] END pca__n_components=2, svm__kernel=linear;, score=0.525 total time=  34.6s\n",
      "[CV 3/3] END pca__n_components=2, svm__kernel=linear;, score=0.537 total time=  31.3s\n",
      "[CV 1/3] END pca__n_components=2, svm__kernel=rbf;, score=0.570 total time=  28.9s\n",
      "[CV 2/3] END pca__n_components=2, svm__kernel=rbf;, score=0.560 total time=  26.8s\n",
      "[CV 3/3] END pca__n_components=2, svm__kernel=rbf;, score=0.564 total time=  26.1s\n",
      "[CV 1/3] END pca__n_components=2, svm__kernel=poly;, score=0.504 total time=  19.1s\n",
      "[CV 2/3] END pca__n_components=2, svm__kernel=poly;, score=0.485 total time=  19.1s\n",
      "[CV 3/3] END pca__n_components=2, svm__kernel=poly;, score=0.492 total time=  19.9s\n",
      "[CV 1/3] END pca__n_components=2, svm__kernel=sigmoid;, score=0.507 total time=  18.0s\n",
      "[CV 2/3] END pca__n_components=2, svm__kernel=sigmoid;, score=0.495 total time=  18.8s\n",
      "[CV 3/3] END pca__n_components=2, svm__kernel=sigmoid;, score=0.505 total time=  20.2s\n",
      "[CV 1/3] END pca__n_components=1, svm__kernel=linear;, score=0.518 total time=  24.5s\n",
      "[CV 2/3] END pca__n_components=1, svm__kernel=linear;, score=0.513 total time=  23.8s\n",
      "[CV 3/3] END pca__n_components=1, svm__kernel=linear;, score=0.525 total time=  21.3s\n",
      "[CV 1/3] END pca__n_components=1, svm__kernel=rbf;, score=0.527 total time=  30.2s\n",
      "[CV 2/3] END pca__n_components=1, svm__kernel=rbf;, score=0.525 total time=  28.4s\n",
      "[CV 3/3] END pca__n_components=1, svm__kernel=rbf;, score=0.529 total time=  30.4s\n",
      "[CV 1/3] END pca__n_components=1, svm__kernel=poly;, score=0.501 total time=  20.9s\n",
      "[CV 2/3] END pca__n_components=1, svm__kernel=poly;, score=0.495 total time=  20.3s\n",
      "[CV 3/3] END pca__n_components=1, svm__kernel=poly;, score=0.499 total time=  21.0s\n",
      "[CV 1/3] END pca__n_components=1, svm__kernel=sigmoid;, score=0.505 total time=  18.3s\n",
      "[CV 2/3] END pca__n_components=1, svm__kernel=sigmoid;, score=0.496 total time=  18.5s\n",
      "[CV 3/3] END pca__n_components=1, svm__kernel=sigmoid;, score=0.500 total time=  18.1s\n",
      "[CV 1/3] END pca__n_components=0.9, svm__kernel=linear;, score=0.600 total time=26.5min\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "\n",
    "grid_search=GridSearchCV(pipeline,param_grid,cv=3,verbose=4) \n",
    "grid_search.fit(x_train,y_train)\n",
    "\n",
    "end_time=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a590806",
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_train\n",
    "del y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a36571",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipeline=grid_search.best_estimator_\n",
    "best_params=grid_search.best_params_\n",
    "best_score=grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters: \",best_params)\n",
    "print(\"beat Score: \",best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7615ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=best_pipeline.score(x_test,y_test)\n",
    "print(\"Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b5fde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=best_pipeline.predict(x_test)\n",
    "\n",
    "target_names=['Cat','Dog']\n",
    "classification_rep= classification_report(y_test,y_pred,target_names=target_names)\n",
    "print(\"Clasiification Report:\\n\",classification_rep)\n",
    "\n",
    "with open(classification_file_path,'w') as file:\n",
    "    file.write(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6d42ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_test,y_pred)\n",
    "sns.heatmap(cm,annot=True,fmt=\"d\",cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True labels\")\n",
    "plt.savefig(confusion_image_path)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
